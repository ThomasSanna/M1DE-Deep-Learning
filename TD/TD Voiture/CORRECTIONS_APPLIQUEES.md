# RÃ©capitulatif des corrections - Dataset Cars

## ðŸ” ProblÃ¨mes identifiÃ©s et corrections appliquÃ©es

### **ProblÃ¨me 1 : Colonnes one-hot encoded de type `bool` au lieu de `float`**

**SymptÃ´me initial :**
- RÂ² = -0.005 (le modÃ¨le ne fait que prÃ©dire la moyenne)
- MSE â‰ˆ 1.0 sur donnÃ©es standardisÃ©es
- PrÃ©dictions constantes (toutes identiques)

**Cause :**
```python
# AVANT (pandas 2.0+ crÃ©e des bool par dÃ©faut)
data = pd.get_dummies(data, columns=...)
```
- CrÃ©ait 382 colonnes `bool` + 6 colonnes `float64`
- `DataFrame.values` retournait un array de type **`object`**
- TensorFlow/Keras ne peut pas calculer les gradients sur un array `object`

**Correction (Cellule 23) :**
```python
# APRÃˆS
data = pd.get_dummies(data, columns=..., dtype=float)
```
âœ… Toutes les colonnes sont maintenant `float64`

---

### **ProblÃ¨me 2 : Normalisation des colonnes one-hot encoded**

**SymptÃ´me :**
- Loss ne descendait pas
- PrÃ©dictions constantes mÃªme aprÃ¨s correction du dtype

**Cause :**
```python
# AVANT - Normalise TOUT !
numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns.tolist()
numeric_cols.remove("Price")
train_data[numeric_cols] = scaler.fit_transform(train_data[numeric_cols])
```
- AprÃ¨s `dtype=float` dans get_dummies, TOUTES les colonnes Ã©taient float64
- StandardScaler normalisait les colonnes one-hot
- `Company Names_audi` passait de `[0, 1]` Ã  `[-0.16, ...]` â†’ dÃ©truit la signification binaire

**Correction (Cellules 24 + 29) :**

**Cellule 24** - DÃ©finir explicitement les colonnes numÃ©riques :
```python
# Liste les colonnes numÃ©riques D'ORIGINE (avant get_dummies)
numeric_features = ['HorsePower', 'Seats', 'Torque', 'Speed', 'Acceleration', 'Battery Capacity']
numeric_features = [col for col in numeric_features if col in data.columns]
```

**Cellule 29** - Scaler SEULEMENT ces colonnes :
```python
# APRÃˆS - Ne normalise QUE les vraies colonnes numÃ©riques
train_data[numeric_features] = scaler.fit_transform(train_data[numeric_features])
test_data[numeric_features] = scaler.transform(test_data[numeric_features])
```
âœ… Les colonnes one-hot restent `[0.0, 1.0]`

---

### **ProblÃ¨me 3 : Valeurs manquantes (NaN) dans Battery Capacity**

**SymptÃ´me :**
- MÃªme aprÃ¨s corrections 1 & 2, le modÃ¨le convergeait vers la moyenne
- Train Loss > Val Loss (anormal)

**Cause :**
- 2 NaN dans la colonne `Battery Capacity` (lignes 671 et 774 du train set)
- Keras/TensorFlow ne peut pas entraÃ®ner avec des NaN
- Propageait des NaN dans les gradients â†’ modÃ¨le bloquÃ©

**Diagnostic effectuÃ© :**
```python
X_train.isna().sum().sum()  # â†’ 2
X_train.values.dtype  # â†’ float64 (mais avec NaN, donc min/max/std = nan)
```

**Correction (Cellule 20) :**
```python
# Remplir les NaN dans Battery Capacity par la mÃ©diane
if 'Battery Capacity' in data.columns and data['Battery Capacity'].isna().sum() > 0:
    median_battery = data['Battery Capacity'].median()
    data['Battery Capacity'].fillna(median_battery, inplace=True)
```
âœ… Plus aucun NaN dans le dataset

---

## ðŸ“Š RÃ©sultat des corrections

### Avant corrections :
- RÂ² = **-0.005** (pire qu'une baseline)
- RMSE â‰ˆ 0.95 (= prÃ©dire la moyenne)
- PrÃ©dictions : toutes identiques (variance â‰ˆ 0)
- Loss stagne Ã  ~1.0 (= variance de y_scaled)

### AprÃ¨s corrections :
- Le modÃ¨le devrait maintenant **apprendre correctement**
- Loss devrait descendre significativement < 0.5
- RÂ² devrait Ãªtre positif et Ã©levÃ© (> 0.6)
- PrÃ©dictions variables selon les inputs

---

## âœ… Liste des modifications dans l'ordre d'exÃ©cution

1. **Cellule 20** : Gestion des NaN dans Battery Capacity (remplacement par mÃ©diane)
2. **Cellule 23** : Ajout de `dtype=float` Ã  `pd.get_dummies()`
3. **Cellule 24** : DÃ©finition explicite de `numeric_features` (6 colonnes seulement)
4. **Cellule 29** : Modification du scaling pour utiliser `numeric_features` au lieu de `numeric_cols`

---

## ðŸŽ¯ Pour vÃ©rifier que tout fonctionne

AprÃ¨s rÃ©-exÃ©cution depuis la cellule 20 :

```python
# 1. VÃ©rifier les types
print(X_train.dtypes.value_counts())  # â†’ Doit afficher "float64: 388"
print(X_train.values.dtype)  # â†’ Doit afficher "float64" (pas "object")

# 2. VÃ©rifier les NaN
print(X_train.isna().sum().sum())  # â†’ Doit afficher 0

# 3. VÃ©rifier les colonnes one-hot
onehot_col = [c for c in X_train.columns if '_' in c][0]
print(X_train[onehot_col].unique())  # â†’ Doit afficher array([0., 1.])

# 4. AprÃ¨s entraÃ®nement, vÃ©rifier les mÃ©triques
print(f"RÂ²: {r2:.4f}")  # â†’ Doit Ãªtre > 0.5
print(f"Train Loss finale: {history.history['loss'][-1]:.4f}")  # â†’ Doit Ãªtre < 0.3
```

---

## ðŸ“ LeÃ§ons apprises

1. **Pandas 2.0+ change de comportement** : `get_dummies()` crÃ©e des `bool` par dÃ©faut â†’ toujours spÃ©cifier `dtype=float` pour ML
2. **Ne JAMAIS normaliser les colonnes one-hot** : elles doivent rester binaires [0, 1]
3. **Toujours vÃ©rifier les NaN** AVANT le split train/test
4. **Diagnostiquer avec `dtype`** : un array numpy de type `object` indique un mÃ©lange de types
5. **Loss â‰ˆ variance** = le modÃ¨le prÃ©dit la moyenne = il n'apprend rien

---

## ðŸ—‘ï¸ Cellules de diagnostic Ã  supprimer (optionnel)

Les cellules suivantes ont Ã©tÃ© ajoutÃ©es pour le diagnostic et peuvent Ãªtre supprimÃ©es :
- Cellule 42 : Diagnostic X_train
- Cellule 43 : Test modÃ¨le avant entraÃ®nement
- Cellule 44 : Test entraÃ®nement 20 epochs
- Cellule 45 : VÃ©rification NaN/Inf
- Cellule 46 : Localisation des NaN

Conserve la **cellule 20** (gestion des NaN) car elle fait partie de la correction permanente !
